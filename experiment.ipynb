{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19e1cbc",
   "metadata": {},
   "source": [
    "Natural Language Processing\n",
    "\n",
    "Why natural language came in to existence?\n",
    "\n",
    "So machine can predict if we give some values or so kind of input data but if the data is in text format the model does not know any luanguage how can it predict the output thats where this NLP came into existance.\n",
    "\n",
    "Use cases:\n",
    "1. Spelling mistakes are automatically corrected when we use this models.\n",
    "2. Automatic replies according to resent conversation.\n",
    "3. text translation-> see translation.\n",
    "4. Alexa and google assistance are the best examples.\n",
    "\n",
    "It became day to day activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d66cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenization in NLP:\n",
    "\n",
    "1. corpus - Paragraph is called corpus.\n",
    "2. documents - sentences is called docuemnts.\n",
    "3. vocobulary - unique words.\n",
    "\n",
    "Tokenization:\n",
    "\n",
    "My name is sandy. I love teaching. - corpus\n",
    "\n",
    "Tokenization->{senteces or documents}\n",
    "\n",
    "1->My name is sandy.\n",
    "2->I love teaching.\n",
    "\n",
    "Tokenization -> words \n",
    "\n",
    "1. My\n",
    "2. name\n",
    "3. is\n",
    "4. Sandy \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLTK - Natural language toolkit\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0453458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Welcome my name is kadha jyothik sandeep. I was learnign Natural language processing.\n",
      "I love learning new things.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus=\"\"\"Hello Welcome my name is kadha jyothik sandeep. I was learnign Natural language processing.\n",
    "I love learning new things.\n",
    "\"\"\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edecdc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sandeep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "314b98c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt', download_dir='C:/nltk_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c0dd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sandeep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt', download_dir=r\"C:\\Users\\Sandeep\\AppData\\Roaming\\nltk_data\")\n",
    "nltk.data.path.append(r\"C:\\Users\\Sandeep\\AppData\\Roaming\\nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47176fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55252037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d7985a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP is amazing.', 'It helps computers understand human language!']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(r\"C:\\Users\\Sandeep\\AppData\\Roaming\\nltk_data\")\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "corpus = \"NLP is amazing. It helps computers understand human language!\"\n",
    "print(sent_tokenize(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac90fbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_kernal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
